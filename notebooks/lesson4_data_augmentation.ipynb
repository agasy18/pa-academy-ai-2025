{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lesson 4: Data Augmentation with CIFAR-10\n",
        "\n",
        "This notebook demonstrates data augmentation techniques using PyTorch and the CIFAR-10 dataset.\n",
        "\n",
        "**Learning objectives:**\n",
        "- Understand why data augmentation improves model generalization\n",
        "- Apply common augmentation transforms to images\n",
        "- Compare model performance with and without augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from fastai.vision.all import *\n",
        "from fastai.callback.all import *\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "set_seed(42, reproducible=True)\n",
        "\n",
        "print(f'PyTorch version: {torch.__version__}')\n",
        "print(f'Using device: {\"cuda\" if torch.cuda.is_available() else \"cpu\"}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load CIFAR-10 Dataset\n",
        "\n",
        "CIFAR-10 consists of 60,000 32×32 color images in 10 classes:\n",
        "- airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download CIFAR-10 dataset\n",
        "path = untar_data(URLs.CIFAR)\n",
        "print(f'Dataset downloaded to: {path}')\n",
        "\n",
        "# CIFAR-10 has 10 classes\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "print(f'Classes: {classes}')\n",
        "print(f'Total images: 60,000 (50,000 train + 10,000 test)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Visualize Original Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a basic DataBlock to visualize original images\n",
        "dblock_viz = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(train_name='train', valid_name='test'),\n",
        "    item_tfms=Resize(32)\n",
        ")\n",
        "\n",
        "dls_viz = dblock_viz.dataloaders(path, bs=16)\n",
        "\n",
        "# Show a batch of images\n",
        "print('Sample images from CIFAR-10:')\n",
        "dls_viz.show_batch(max_n=16, nrows=2, figsize=(14, 6))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Common Data Augmentation Techniques\n",
        "\n",
        "Augmentation artificially expands the training set by applying random transformations:\n",
        "- **RandomHorizontalFlip**: Flips images left-right\n",
        "- **RandomCrop**: Crops random patches from images\n",
        "- **ColorJitter**: Randomly changes brightness, contrast, saturation\n",
        "- **RandomRotation**: Rotates images by random angles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create augmentation pipeline using FastAI\n",
        "# aug_transforms provides common augmentations for computer vision\n",
        "aug_tfms = aug_transforms(\n",
        "    size=32,\n",
        "    do_flip=True,          # Random horizontal flip\n",
        "    flip_vert=False,       # Don't flip vertically (objects don't appear upside down)\n",
        "    max_rotate=15.0,       # Random rotation up to 15 degrees\n",
        "    max_lighting=0.3,      # Brightness/contrast adjustments\n",
        "    max_warp=0.2,          # Perspective warping\n",
        "    p_affine=0.75,         # Probability of applying geometric transforms\n",
        "    p_lighting=0.75        # Probability of applying lighting transforms\n",
        ")\n",
        "\n",
        "print('Augmentation transforms configured:')\n",
        "print('- Random horizontal flips')\n",
        "print('- Random crops with padding')\n",
        "print('- Random rotations (±15°)')\n",
        "print('- Brightness and contrast adjustments')\n",
        "print('- Perspective warping')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Compare Original vs Augmented Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataBlock with augmentation to visualize the effects\n",
        "dblock_aug_viz = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(train_name='train', valid_name='test'),\n",
        "    item_tfms=Resize(32),\n",
        "    batch_tfms=[*aug_tfms, Normalize.from_stats(*cifar_stats)]\n",
        ")\n",
        "\n",
        "dls_aug_viz = dblock_aug_viz.dataloaders(path, bs=16)\n",
        "\n",
        "# Visualize augmented images\n",
        "print('Same images with augmentation applied:')\n",
        "dls_aug_viz.show_batch(max_n=16, nrows=2, figsize=(14, 6))\n",
        "\n",
        "print('\\nNotice the variations:')\n",
        "print('- Some images are flipped horizontally')\n",
        "print('- Images have different brightness/contrast')\n",
        "print('- Slight rotations and perspective changes')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Data with FastAI\n",
        "\n",
        "FastAI provides a cleaner API for data loading and augmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract CIFAR-10 to a standard location\n",
        "path = untar_data(URLs.CIFAR)\n",
        "print(f'Data path: {path}')\n",
        "\n",
        "# Create DataBlock WITHOUT augmentation (baseline)\n",
        "dblock_basic = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(train_name='train', valid_name='test'),\n",
        "    item_tfms=Resize(32),\n",
        "    batch_tfms=[Normalize.from_stats(*cifar_stats)]\n",
        ")\n",
        "\n",
        "dls_basic = dblock_basic.dataloaders(path, bs=128)\n",
        "print(f'Training batches: {len(dls_basic.train)}')\n",
        "print(f'Validation batches: {len(dls_basic.valid)}')\n",
        "print(f'Classes: {dls_basic.vocab}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize with FastAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FastAI's built-in visualization\n",
        "dls_basic.show_batch(max_n=16, nrows=2, figsize=(12, 6))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Define Inception-based Model\n",
        "\n",
        "We'll use a pretrained Inception (Xception) architecture, adapted for CIFAR-10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create learner with Inception (xresnet) architecture\n",
        "# xresnet is FastAI's improved version of ResNet with Inception-like improvements\n",
        "learn_basic = vision_learner(\n",
        "    dls_basic, \n",
        "    xresnet18,  # Inception-inspired architecture\n",
        "    metrics=[accuracy, error_rate],\n",
        "    loss_func=CrossEntropyLossFlat()\n",
        ")\n",
        "\n",
        "print(f'Model: xresnet18 (Inception-inspired architecture)')\n",
        "print(f'Total parameters: {sum(p.numel() for p in learn_basic.model.parameters()):,}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train Without Augmentation (Baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training WITHOUT augmentation...')\n",
        "learn_basic.fine_tune(10, base_lr=3e-3, freeze_epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Create DataLoader WITH Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create DataBlock WITH augmentation using FastAI's aug_transforms\n",
        "dblock_augmented = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items=get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(train_name='train', valid_name='test'),\n",
        "    item_tfms=Resize(32),\n",
        "    batch_tfms=[\n",
        "        *aug_transforms(\n",
        "            size=32,\n",
        "            do_flip=True,\n",
        "            flip_vert=False,\n",
        "            max_rotate=15.0,\n",
        "            max_lighting=0.3,\n",
        "            max_warp=0.2,\n",
        "            p_affine=0.75,\n",
        "            p_lighting=0.75\n",
        "        ),\n",
        "        Normalize.from_stats(*cifar_stats)\n",
        "    ]\n",
        ")\n",
        "\n",
        "dls_augmented = dblock_augmented.dataloaders(path, bs=128)\n",
        "\n",
        "# Visualize augmented samples\n",
        "print('Augmented training samples:')\n",
        "dls_augmented.show_batch(max_n=16, nrows=2, figsize=(12, 6))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Train WITH Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Training WITH augmentation...')\n",
        "learn_augmented = vision_learner(\n",
        "    dls_augmented, \n",
        "    xresnet18,\n",
        "    metrics=[accuracy, error_rate],\n",
        "    loss_func=CrossEntropyLossFlat()\n",
        ")\n",
        "\n",
        "learn_augmented.fine_tune(10, base_lr=3e-3, freeze_epochs=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Compare Results\n",
        "\n",
        "FastAI automatically tracks training history. Let's visualize and compare.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history for both models\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Extract losses\n",
        "basic_losses = [x['train_loss'] for x in learn_basic.recorder.values]\n",
        "aug_losses = [x['train_loss'] for x in learn_augmented.recorder.values]\n",
        "\n",
        "# Extract accuracies (convert to percentage)\n",
        "basic_acc = [x['accuracy'] * 100 for x in learn_basic.recorder.values]\n",
        "aug_acc = [x['accuracy'] * 100 for x in learn_augmented.recorder.values]\n",
        "\n",
        "# Plot training loss\n",
        "ax1.plot(basic_losses, label='Without Augmentation', marker='o', linewidth=2)\n",
        "ax1.plot(aug_losses, label='With Augmentation', marker='s', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Training Loss', fontsize=12)\n",
        "ax1.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot validation accuracy\n",
        "ax2.plot(basic_acc, label='Without Augmentation', marker='o', linewidth=2)\n",
        "ax2.plot(aug_acc, label='With Augmentation', marker='s', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Validation Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Validation Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'\\nFinal Results:')\n",
        "print(f'Without Augmentation: {basic_acc[-1]:.2f}% accuracy')\n",
        "print(f'With Augmentation: {aug_acc[-1]:.2f}% accuracy')\n",
        "print(f'Improvement: {aug_acc[-1] - basic_acc[-1]:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Visualize Predictions\n",
        "\n",
        "Let's see how each model performs on test images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show predictions from augmented model\n",
        "learn_augmented.show_results(max_n=12, figsize=(14, 10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Confusion Matrix\n",
        "\n",
        "Analyze which classes are most commonly confused.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get interpretation for augmented model\n",
        "interp = ClassificationInterpretation.from_learner(learn_augmented)\n",
        "\n",
        "# Plot confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "interp.plot_confusion_matrix(figsize=(10, 10))\n",
        "plt.show()\n",
        "\n",
        "# Show most confused classes\n",
        "print('\\nMost confused pairs:')\n",
        "interp.most_confused(min_val=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Understanding the Inception Architecture\n",
        "\n",
        "The xresnet architecture includes Inception-inspired improvements:\n",
        "- **Depthwise separable convolutions**: More efficient than standard convolutions\n",
        "- **Residual connections**: Help with gradient flow\n",
        "- **Batch normalization**: Stabilizes training\n",
        "- **Global average pooling**: Reduces parameters vs fully connected layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect model architecture\n",
        "print('Model Architecture Summary:')\n",
        "print(learn_augmented.model)\n",
        "print(f'\\nTotal trainable parameters: {sum(p.numel() for p in learn_augmented.model.parameters() if p.requires_grad):,}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Data augmentation** artificially expands the training set without collecting new data\n",
        "2. **Common techniques**: flips, crops, rotations, color/lighting adjustments, warping\n",
        "3. **Benefits**: Better generalization, reduced overfitting, improved test accuracy\n",
        "4. **Inception architectures**: Use efficient depthwise separable convolutions and residual connections\n",
        "5. **FastAI advantages**: Simplified API, automatic mixed precision, learning rate scheduling\n",
        "6. **Best practice**: Apply augmentation only to training data, not validation/test data\n",
        "7. **Transfer learning**: Fine-tuning pretrained models significantly improves performance on small datasets\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
