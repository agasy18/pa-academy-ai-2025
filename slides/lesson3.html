<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lesson 3 — Activation and Loss Functions</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5/dist/theme/white.css" id="theme">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@5/plugin/highlight/monokai.css">
    <style>
      .reveal section pre code { font-size: 0.8em; line-height: 1.3; }
      .small { font-size: 0.8em; }
    </style>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section>
          <h2>Lesson 3: Activation and Loss Functions</h2>
          <h3>Learning Objectives</h3>
          <ul>
            <li>Why networks need nonlinear activations</li>
            <li>Compare Sigmoid, Tanh, ReLU</li>
            <li>Choose proper loss by task</li>
          </ul>
        </section>

        <section>
          <h3>Concept</h3>
          <p>Without activation → one big linear model. Nonlinearity enables complex boundaries.</p>
        </section>

        <section>
          <h3>Activations</h3>
          <ul>
            <li>Sigmoid: smooth, saturates; outputs [0,1]</li>
            <li>Tanh: zero-centered; still saturates</li>
            <li>ReLU: simple, avoids saturation but can die</li>
          </ul>
        </section>

        <section>
          <h3>Loss Functions</h3>
          <ul>
            <li>MSE: average squared error (regression)</li>
            <li>Cross-Entropy: penalizes overconfident mistakes (classification)</li>
          </ul>
        </section>

        <section>
          <h3>Hands-On</h3>
          <p>Swap activations and observe accuracy; try both losses.</p>
        </section>

        <section>
          <h3>Wrap-Up</h3>
          <p>Quick quiz / pair explain activity.</p>
          <p class="small"><strong>Homework:</strong> 3-line summaries per activation; remove one activation layer and visualize the effect.</p>
        </section>

      </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5/dist/reveal.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5/plugin/notes/notes.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@5/plugin/highlight/highlight.js"></script>
    <script>
      Reveal.initialize({
        hash: true,
        slideNumber: true,
        transition: 'slide',
        plugins: [RevealNotes, RevealHighlight]
      });
    </script>
  </body>
  </html>

